---
title: "Multiclass Lab Notebook"
author: "Codie Wood"
date: "2023-01-11"
output: 
  pdf_document:
    keep_tex: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      dev = 'pdf',
                      pdf.options(encoding = "ISOLatin9.enc"))
```

# Multi-class Classification

```{r, include = FALSE}
# Clear work environment to reset from previous sections
rm(list = ls())
```

In this section we consider the multi-class classification task of predicting the type of a reported crime, given data on the crime. We also extend this to address the secondary question of if we can predict the time of day at which a crime occurRed, given data on the crime. We will focus here on the method of multinomial logistic regression for both of these tasks.

Firstly, we perform feature selection by manual investigation of our variables. We will identify variables to include in our classifier, taking into account both their real world interpretations and computational complexity of the model. We will select several feasible models, and use multiple metrics to assess their performance. We will use repeated $k$-fold cross validation to calculate average values of these metrics across different training sets. We will then compare our models using these averages.

```{r}
devtools::install_github("codiewood/chicago_crime/chicri")
library(chicri)
```


```{r}
#wont need this when loading package
#require(tidyverse) # For data manip
#require(lubridate) # For date/time
#require(ggplot2) # For plots
#require(sf) # For spatial plots
#require(caret) # For confusion matrix
theme_set(theme_minimal())
```

## Feature Selection

Due to the extremely large size of the full data set, it is computationally intensive to download, store and use to train models. As such, we instead train and test the multinomial logistic regression models only on data from 2019.

```{r, include=FALSE}
# data I want here should be a tibble format, with vars primary type, location desc, district, date, arrest, domestic, x coord and y coord. if different, will need to tweak code later on.
dat <- load_crimes_csv("chicri/data/processed/Crimes_2019_Location_Type.csv")
```

```{r, eval=FALSE}
dat <- load_crimes_API(year="2019")
vars_to_remove <- c("ID", "Case Number", "Block", "IUCR", "FBI Code", "Description", "Beat", "Ward", "Community Area", "Updated On", "Latitude", "Longitude", "Location", "Year")
dat <- process_data(dat) %>%
  select(-all_of(vars_to_remove))
```

As well as the data pre-processing described earlier in the report, we also perform additional feature selection for this particular task.

### Primary Type

```{r}
# Reorders type factor for plotting and analysis
dat$`Primary Type` <- fct_infreq(dat$`Primary Type`) %>% fct_rev()

thr <- 1000 # set threshold for othering

ggplot(dat) +
  geom_bar(aes(y = `Primary Type`)) +
  geom_vline(xintercept=thr, colour="red")
```

We observe that there are initially 31 crime types as classified in our data set. Of these, 14 types have fewer than 1000 observations. In order to reduce the computational complexity of our model, we merge these uncommon levels of our factor variable into the level OTHER, in which we also include the pre-existing crime type OTHER OFFENSE. This leaves us with a total of 17 levels in our variable, with 7.57% of data values in the OTHER category. The least frequent category is SEX OFFENSE, which has 1310 occurences.

```{r}
# Reordering and othering factor levels (for plots and analysis purposes)
dat$`Primary Type` <- fct_recode(dat$`Primary Type`,"OTHER" = "OTHER OFFENSE") %>%
  othering(thr,print_summary = T) %>%
  fct_infreq() %>%
  fct_rev()

ggplot(dat) +
  geom_bar(aes(y = `Primary Type`))
```

### Location Description
We also wished to reduce the number of levels for the Location Descriptions in our data set. Initially, we have 156 location descriptions. Of these, 127 have less than 1000 observations. In order to reduce the computational complexity of our model, we merge these uncommon levels of our factor variable into the level OTHER, as well as merging some groups which have similar categories: for example, all descriptions containing the word "airport" were merged into one category. 
```{r}
# Reordering factor levels (for plots and analysis purposes)
dat$`Location Description` <- fct_infreq(dat$`Location Description`) %>%
  fct_rev()

ggplot(dat) +
  geom_bar(aes(y = `Location Description`)) +
  geom_vline(xintercept=thr, colour="red")
```

```{r}
dat <- regroup_locations(dat,thr)

dat$`Location Description` <- fct_infreq(dat$`Location Description`) %>% fct_rev()

ggplot(dat) +
  geom_bar(aes(y = `Location Description`))
```

Even after this removal of categories, after some exploration we found that inclusion in the model led to an inability for the model to converge, and so we remove this from our final analysis.

### District

```{r}
# Loading mapping data for plots
district_map <- RSocrata::read.socrata("https://data.cityofchicago.org/resource/24zt-jpfn.csv")
```

In order to include spatial information, we consider the District variable. We observe that all districts experience reasonable numbers of crimes to be incorporated into analysis, with the exception of District 031. 

```{r}
district_map <- district_map %>%
  select(c(the_geom, District = dist_num)) %>%
  st_as_sf(wkt = "the_geom") 
plot_heat_map_d(district_map,"District")
```

This district is made up of multiple different areas, as can be seen in the geographical plots. In order to simplify analysis, we exclude the 7 crimes from District 031, and simply note that as a result our model will not be suitable for prediction in this district. As such we are left with 22 districts in our analysis.

```{r}
# Reordering factor levels (for plots and analysis purposes)
dat$District <- dat$District %>%
  fct_infreq() %>%
  fct_rev()

ggplot(dat) +
  geom_bar(aes(y = District))
```

```{r}
# Removing district 31 from analysis
dat <- dat[dat$District != "031",]
dat$District <- fct_drop(dat$District)
```

In order to reduce the computational complexity of our model, whilst still maintaining location information, we can also consider grouping districts further into policing district areas, of which there are 5. 

BEEP Source http://oururbantimes.com/district-stations/command-changes-12th-and-14th-chicago-police-department-districts

https://news.wttw.com/2020/04/30/chicago-police-opening-2-new-operation-areas-expand-resources-across-city BEEP

```{r}
# Adding area groupings
area1 <- c("002","003","008","009","007")
area2 <- c("004","005","006","022")
area3 <- c("001","012","018","019","020","024")
area4 <- c("010","011","015")
area5 <- c("014","016","017","025")
dat$`District Area` <- fct_collapse(dat$District, "AREA 1" = area1, "AREA 2" = area2, "AREA 3" = area3, "AREA 4"= area4, "AREA 5" = area5) %>%
  fct_relevel(sort)
```


```{r}
district_map$Area <- fct_collapse(as.factor(district_map$District),
                                  "AREA 1" = as.character(as.integer(area1)),
                                  "AREA 2" = as.character(as.integer(area2)),
                                  "AREA 3" = as.character(as.integer(area3)),
                                  "AREA 4"= as.character(as.integer(area4)),
                                  "AREA 5" = as.character(as.integer(area5))) %>%
  fct_relevel(sort) %>%
  fct_relevel("31", after = Inf)

#Plot for just area
area_plot <- plot_heat_map_d(district_map,"Area")
area_plot
```


```{r}
# Get district labels and locations
district_labels <- sort(as.integer(district_map$District))
district_markers <- district_map %>%
  dplyr::arrange(as.integer(District)) %>%
  sf::st_centroid() %>%
  sf::st_coordinates() %>%
  as_tibble() %>%
  dplyr::mutate(district_labels = district_labels)

# Plot with district labels and coloured area: labels for 31 are a bit vom
area_plot_markers <- area_plot +
  geom_sf(data = district_map, aes(fill = Area)) +
    scale_fill_viridis_d(name = "Area",option = "magma") +
  geom_point(data = district_markers, aes(X, Y), size = 7, shape=22, fill = "Grey", alpha=0.7) +
  geom_text(data = district_markers, aes(X, Y, label = district_labels)) +
  theme_void()

area_plot_markers
```

```{r}
# Plot showing number of crimes in each district area
ggplot(dat) +
  geom_bar(aes(y = `District Area`))
```

As we are choosing to encode location in our model via district and district area, in order to reduce computational costs and reduce redundancy in our model we will not consider the X and Y coordinates so drop them from our analysis.

```{r}
dat <- select(dat, -c(`X Coordinate`,`Y Coordinate`))
```

### Time and Date

In order to incorporate temporal data, we include the date as the day of the year, `Day`, as well as time of day,`Time`. We standardize both of these variables to take values between 0 and 1. This is to ensure the convergence rate is not slow when we fit our model.

In order to facilitate our second model, which attempts to predict the time of day at which a crime occurs, we also add the variable `Time of Day` which encodes the time as a categorical variable with the following levels:
* `MORNING`: between 5am and 12 noon
* `AFTERNOON`: between 12 noon and 5pm
* `EVENING`: between 5pm and 9pm
* `NIGHT`: between 9pm and 5am

After this processing, we then remove the `Date` variable.

```{r}
t <- lubridate::hour(dat$Date) + lubridate::minute(dat$Date)/60
tod <- rep("NIGHT",length(t))
for(i in 1:length(t)){
  if(5 <= t[i] & t[i] < 12){
    tod[i] <- "MORNING"
    }
  else if(12 <= t[i] & t[i] < 17){
    tod[i] <- "AFTERNOON"
    }
  else if(17 <= t[i] & t[i] < 21){
    tod[i] <- "EVENING"
    }
}
tod <- as.factor(tod)
```

```{r}
dat <- dat %>%
  mutate(dat,
         Day = yday(dat$Date) / 365,
         Time = t/24,
         `Time of Day` = tod) %>%
  select(-Date)
```

```{r}
# Plot showing number of crimes at times of day
ggplot(dat) +
  geom_bar(aes(y = `Time of Day`))
```

## Multinomial Logistic Regression

We use the `multinom()` function from the `nnet` package in order to implement multinomial logistic regression. We calculate various model performance metrics using the `confusionMatrix()` function from the `caret` package. Namely we focus here on calculating overall accuracy and no-information rate (NIR), as well as class specific sensitivity, specification and accuracy values. We implement 5-fold repeated cross validation, with $n = 5$ repeats, and calculate the average of each metric across all folds for each repeat.

```{r}
#setting seed for reproducibility
set.seed(200899)
metrics <- c("Sensitivity", "Specificity", "Balanced Accuracy")
```

### Predicting Crime Type

We begin by splitting our data into our response variable and the variables we want to include in our models. We look at three potential models:
1. No Location: Primary Type ~ Arrest + Domestic + Day + Time
2. District Area: Primary Type ~ Arrest + Domestic + Day + Time + District Area
3. District: Primary Type ~ Arrest + Domestic + Day + Time + District

```{r}
# Splitting response data and different model variable sets
y <- dat$`Primary Type`
X_noloc <- dat %>% select(c(Arrest, Domestic, Day, Time))
X_area <- dat %>% select(c(Arrest, Domestic, Day, Time, `District Area`))
X_district <- dat %>% select(c(Arrest, Domestic, Day, Time, District))
```

We evaluate the model performance using the `mnlr_kfold_cv.df()` function, which outputs a data frame containing the metrics as evaluated for the model fitted on each fold for each repeat. Our package also contains the `mnlr_kfold_cv.list()` function, which performs the same operations and outputs a list based format of our values, as well as their averages. We use the data frame function for our analysis, however, as its output can be easily manipulated to calculate averages, investigate metric distributions. Further, the data frame outputs can be easily converted into an easy to read table, ideal for producing result documentation, which the list output cannot.

```{r, eval=FALSE}
mnlr_results_noloc.df <- mnlr_kfold_cv.df(X = X_noloc, y = y, k = 5, n_reps = 5, metrics = metrics)
```

```{r, eval = FALSE}
mnlr_results_area.df <- mnlr_kfold_cv.df(X = X_area, y = y, k = 5, n_reps = 5, metrics = metrics)
```

```{r, eval=FALSE}
mnlr_results_district.df <- mnlr_kfold_cv.df(X = X_district, y = y, k = 5, n_reps = 5, metrics = metrics)
```

```{r, include = FALSE}
load("chicri/temp_data/mnlr_results_noloc_df.RData")
load("chicri/temp_data/mnlr_results_area_df.RData")
load("chicri/temp_data/mnlr_results_district_df.RData")
```

We then create tables of our results, using the `mean_report_metrics()` function, and then for the class means we also average over the repeats.

```{r}
noloc_class_means <- mean_repeat_metrics(mnlr_results_noloc.df, type = "class")
noloc_overall_means <- mean_repeat_metrics(mnlr_results_noloc.df, type = "overall")
```

```{r}
noloc_avg_class_means <- noloc_class_means %>%
  dplyr::summarise("Average Sensitivity" = mean(`Average Sensitivity`),
                   "Average Specificity" = mean(`Average Specificity`),
                   "Average Balanced Accuracy" = mean(`Average Balanced Accuracy`))
```

We use the `knitr::kable()` functionality, as well as the `kableExtra` package, to export our results into a format suitable for our report: namely, a latex table. This is contained within the `read_table()` function.

```{r}
noloc_kab <- report_table(noloc_overall_means, rep("c",4))
noloc_kab
```

```{r}
noloc_kab_class <- report_table(noloc_avg_class_means, c("l",rep("c",3)))
noloc_kab_class
```

We repeat this process for each of our 3 models.

```{r}
area_class_means <- mean_repeat_metrics(mnlr_results_area.df, type = "class")
area_overall_means <- mean_repeat_metrics(mnlr_results_area.df, type = "overall")
```

```{r}
area_avg_class_means <- area_class_means %>%
  dplyr::summarise("Average Sensitivity" = mean(`Average Sensitivity`),
                   "Average Specificity" = mean(`Average Specificity`),
                   "Average Balanced Accuracy" = mean(`Average Balanced Accuracy`))
```

```{r}
area_kab <- report_table(area_overall_means, rep("c",4))
area_kab
```

```{r}
area_kab_class <- report_table(area_avg_class_means,c("l",rep("c",3)))
area_kab_class
```

```{r}
district_class_means <- mean_repeat_metrics(mnlr_results_district.df, type = "class")
district_overall_means <- mean_repeat_metrics(mnlr_results_district.df, type = "overall")
```

```{r}
district_avg_class_means <- district_class_means %>%
  dplyr::summarise("Average Sensitivity" = mean(`Average Sensitivity`),
                   "Average Specificity" = mean(`Average Specificity`),
                   "Average Balanced Accuracy" = mean(`Average Balanced Accuracy`))
```

```{r}
district_kab <- report_table(district_overall_means, rep("c",4))
district_kab
```

```{r}
district_kab_class <- report_table(district_avg_class_means, c("l",rep("c",3)))
district_kab_class
```

We observe that, whilst there is a progressive increase in the overall accuracy of the models, the increase from using `District Area` to using `District` is very marginal. As such, we prefer to use the model which includes location as `District Area` as this balances accuracy with computational cost.

Next, we perform further analysis on our chosen model. We refit our model using a training data set, using an 80-20 split of training to test data.

```{r, eval=FALSE}
set.seed(1)
ind <- sample(2,nrow(dat),replace=TRUE, prob = c(0.8,0.2))
index <- which(ind == 2)
mnlr <- mnlr_cv_indexed(X_area,y,index,return_model = TRUE)
```

```{r, include=FALSE}
load("chicri/temp_data/mnlr_area_model.RData")
```
We can look at a subset of the predictive probabilities produced by the model, as well as the coefficient values, in order to interpret the relationships between our observed variables and the log odds of a particular class. We can also extract data from our `confusionMatrix` object to produce a confusion matrix plot, which shows the frequency of various prediction and reference combinations.

BEEP might not want to print these as it is large BEEP
```{r}
head(pp <- fitted(mnlr$model)) # Predictive probabilities
```

```{r}
coef(mnlr$model) # Coefficients
```

```{r}
# Extract confusion matrix for plot
tab <- mnlr$conf.matrix$table
confusion_df <- as.data.frame(tab)

confusion_plot <- ggplot(confusion_df, aes(x=Reference, y = Prediction, fill=Freq)) +
  coord_equal() +
  geom_tile() +
  labs(title = "Prediction distribution") +
  scale_y_discrete(limits = rev) +
  scale_x_discrete(expand = expansion(mult = c(0,0)), guide = guide_axis(angle = 45)) +
  geom_text(aes(label=Freq), color="black") # printing values
confusion_plot
```

## Predicting Time of Crime

As an extension to this multiclass classification task, we will also evaluate the performance of another multinomial regression classifier used to predict the time of day at which a crime occurred. We use the same methods as seen previously but now time of day is response variable and we exclude Time from our model. This gives us the three models:
1. No Location: Time of Day ~ Primary Type + Arrest + Domestic + Day
2. District: Time of Day ~ Primary Type + Arrest + Domestic + Day + District
3. District Area: Time of Day ~ Primary Type + Arrest + Domestic + Day + District Area

We repeat the exact steps as when we considered the `Primary Type` response variable.

```{r}
#setting seed for reproducibility
set.seed(200899)
# Splitting response data and different model variable sets
y_tod <- dat$`Time of Day`
X_tod_noloc <- dat %>% select(c(`Primary Type`,Arrest,Domestic,Day))
X_tod_area <- dat %>% select(c(`Primary Type`,Arrest,Domestic,Day,`District Area`))
X_tod_district <- dat %>% select(c(`Primary Type`,Arrest,Domestic,Day,District))
```

BEEP this has 60 variables and converges (but other models none converged) BEEP
```{r, eval=FALSE}
tod_results_noloc <- mnlr_kfold_cv.df(X = X_tod_noloc, y = y_tod, k = 5, n_reps = 5, metrics = metrics)
```

BEEP this has 72 variables and converges BEEP
```{r, eval = FALSE}
tod_results_area <- mnlr_kfold_cv.df(X = X_tod_area, y = y_tod, k = 5, n_reps = 5, metrics = metrics)
```

BEEP this has 123 variables BEEP
```{r, eval=FALSE}
tod_results_district <- mnlr_kfold_cv.df(X = X_tod_district, y = y_tod, k = 5, n_reps = 5, metrics = metrics)
```
BEEP need to run the above and save then find best and do plots as before BEEP

```{r, include = FALSE}
load("chicri/temp_data/tod_results_noloc.RData")
load("chicri/temp_data/tod_results_area.RData")
load("chicri/temp_data/tod_results_district.RData")
```

```{r}
tod_noloc_class_means <- mean_repeat_metrics(tod_results_noloc,type="class")
tod_noloc_overall_means <- mean_repeat_metrics(tod_results_noloc,type="overall")
```

```{r}
tod_noloc_avg_class_means <- tod_noloc_class_means %>%
  dplyr::summarise("Average Sensitivity" = mean(`Average Sensitivity`),
                   "Average Specificity" = mean(`Average Specificity`),
                   "Average Balanced Accuracy" = mean(`Average Balanced Accuracy`))
```


```{r}
tod_noloc_kab <- report_table(tod_noloc_overall_means, rep("c",4))
tod_noloc_kab
```

```{r}
tod_noloc_kab_class <- report_table(tod_noloc_avg_class_means, c("l",rep("c",3)))
tod_noloc_kab_class
```

```{r}
tod_area_class_means <- mean_repeat_metrics(tod_results_area,type="class")

tod_area_overall_means <- mean_repeat_metrics(tod_results_area,type="overall")
```

```{r}
tod_area_avg_class_means <- tod_area_class_means %>%
  dplyr::summarise("Average Sensitivity" = mean(`Average Sensitivity`),
                   "Average Specificity" = mean(`Average Specificity`),
                   "Average Balanced Accuracy" = mean(`Average Balanced Accuracy`))
```


```{r}
tod_area_kab <- report_table(tod_area_overall_means, rep("c",4))
tod_area_kab
```

```{r}
tod_area_kab_class <- report_table(tod_area_avg_class_means, c("l",rep("c",3)))
tod_area_kab_class
```


```{r}
tod_district_class_means <- mean_repeat_metrics(tod_results_district,type="class")

tod_district_overall_means <- mean_repeat_metrics(tod_results_district,type="overall")
```

```{r}
tod_district_avg_class_means <- tod_district_class_means %>%
  dplyr::summarise("Average Sensitivity" = mean(`Average Sensitivity`),
                   "Average Specificity" = mean(`Average Specificity`),
                   "Average Balanced Accuracy" = mean(`Average Balanced Accuracy`))
```


```{r}
tod_district_kab <- report_table(tod_district_overall_means, rep("c",4))
tod_district_kab
```

```{r}
tod_district_kab_class <- report_table(tod_district_avg_class_means, c("l",rep("c",3)))
tod_district_kab_class
```


Each of the models have similar overall accuracy across our repeats, so we prefer the simplest model with the fewest variables as this has minimal computational cost to run.
```{r, eval=FALSE}
set.seed(1)
ind <- sample(2,nrow(dat),replace=TRUE, prob = c(0.8,0.2))
index <- which(ind == 2)
tod_mnlr <- mnlr_cv_indexed(X_tod_noloc,y_tod,index,return_model = TRUE)
```

```{r, include=FALSE}
load("chicri/temp_data/tod_noloc_model.RData")
```

```{r}
head(tod_pp <- fitted(tod_mnlr$model)) #Predictive probabilities for each obs
```

```{r}
coef(tod_mnlr$model)
```

```{r}
# Extract confusion matrix for plot
tod_tab <- tod_mnlr$conf.matrix$table
tod_confusion_df <- as.data.frame(tod_tab)

tod_confusion_plot <- ggplot(tod_confusion_df, aes(x=Reference, y = Prediction, fill=Freq)) +
  coord_equal() +
  geom_tile() +
  labs(title = "Prediction distribution") +
  scale_y_discrete(limits = rev) +
  scale_x_discrete(expand = expansion(mult = c(0,0)), guide = guide_axis(angle = 45)) +
  geom_text(aes(label=Freq), color="black") # printing values

tod_confusion_plot
```

