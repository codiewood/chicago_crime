---
title: Rachel section
author: Rachel
date: 
output: pdf_document
---
# Regression on Spatial Data

## Overview of Data

Chicago has 77 neighbourhoods, which are called community areas. We can use the `read.socrata()` function to obtain the map of community areas from the Chicago Data Portal in the form of shapefiles:

```{r}
library(tidyverse)
library(RSocrata)
library(sf)
community_map <- read.socrata("https://data.cityofchicago.org/resource/igwz-8jzy.csv")
community_map <- community_map %>% select(c(the_geom, area = area_numbe)) %>% st_as_sf(wkt = "the_geom")
```

We can also obtain a record of 3 socio-economic indicators for each of the community areas for the years 2007-2011

We can see there are 3 socio-economic indicators provided for each community area:

 More information on how this is calculated can be found in \textbf{REVISIT}
 
We now plot the map of chicago with respect to these indicators:
```{r}

library(gridExtra)
community_info <- left_join(community_map, socio_ind, by = c("area" = "ca"))

poverty_plot <- plot_heat_map(data = community_info, variable = "percent_households_below_poverty", legend.title = "Households \n in \n Poverty \n (%)", trans = "reverse")

income_plot <- plot_map(data = community_info, variable = "per_capita_income_", 
                         legend.title = "Per Capita \n Income ($)")

hardship_plot <- plot_map(data = community_info, variable = "hardship_index", 
                         legend.title = "Hardship \n Index", trans = "reverse")

grid.arrange(poverty_plot, income_plot, hardship_plot, nrow = 1)
```


# Poisson General Additive Models

To fit this class of models, we use the `gam()` function from the `mgcv` package. For this task we first attempt to fit a regression model to predict the number of crimes to occur in any given week or month, then incorporating a spatial dimension to these predictions using the community areas and latitude and longitude co-ordinates.

## Predictions in Time

```{r}
count_cases <- function(df, date_start = NULL, date_end = NULL, location_level =NULL, date_level = "month"){
  location_level <- enquo(location_level)
  
  if (is.null(date_start)){ #if no start date, set to before first observation in data
    date_start <- as.Date("01-01-2000")
  }
  if (is.null(date_end)){ #if no end date, set to current date
    date_end <- Sys.Date()
  }

  if (is.null(location_level)){ #if not including location
    if (date_level == "day"){ #if day selected
      count_dat <- df %>% 
        filter(date > date_start, date < date_end) %>% 
        mutate(year = year(date), month = month(date), yday = day(date)) %>%
        group_by(year, month,day) %>%
        dplyr::summarise(count = n())
    } else if (date_level == "week") { #if week selected
      count_dat <- df %>% 
        filter(date > date_start, date < date_end) %>% 
        mutate(week_start = floor_date(date, unit = "week", week_start = 1)) %>%
        group_by(week_start) %>%
        dplyr::summarise(count = n()) %>%
        mutate(year = year(week_start), week = week(week_start))
    } else if (date_level == "month"){ #if month selected
      count_dat <- df %>% 
        filter(date > date_start, date < date_end) %>% 
        mutate(year = year(date), month = month(date)) %>%
        group_by(year, month) %>%
        dplyr::summarise(count = n())
    }
  } else { #if we do include location

    if (date_level == "day"){
      count_dat <- df %>% 
        filter(Date > date_start, Date < date_end) %>% 
        mutate(year = year(date), month = month(date), day = day(date)) %>%
        group_by(year, month,day, !!eval(location_level)) %>%
        dplyr::summarise(count = n())
    } else if (date_level == "week") {
      count_dat <- df %>% 
        filter(date > date_start, date < date_end) %>% 
        mutate(week_start = floor_date(date, unit = "week", week_start = 1)) %>%
        group_by(week_start, !!eval(location_level)) %>%
        dplyr::summarise(count = n()) %>%
        mutate(year = year(week_start), week = week(week_start))
    } else if (date_level == "month"){
      count_dat <- df %>% 
        filter(date > date_start, date < date_end) %>% 
        mutate(year = year(date), month = month(date)) %>%
        group_by(year, month, !!eval(location_level)) %>%
        dplyr::summarise(count = n())
    }
  }
  
  return(count_dat)
}


```


```{r}

week_data <- data_API %>% count_cases(date_level = "week")


model_week <- gam(count ~ s(week, bs = "cc") + as.numeric(year), data = week_data, family = "poisson")

week_data <- cbind(week_data, "predicted" = model_week$fitted)

week_plot <- ggplot(data = week_data) +
  geom_point(aes(x = week_start, y = count), color = "steelblue3", alpha =0.5) +
  geom_line(aes(x = week_start, y = predicted)) 


month_data <- data_API %>% count_cases(date_level = "month")

model_month <- gam(count ~ s(month, bs = "cc") + as.numeric(year), data = month_data, family = "poisson")

month_data <- cbind(month_data, "predicted" = model_month$fitted) %>%
  mutate(month = as.yearmon(str_c(year, "-", month))) %>%
  ungroup() %>%
  select(!(year))

month_plot <- ggplot(data = month_data) +
  geom_point(aes(x = month, y = count), color = "steelblue3", alpha =0.5) +
  geom_line(aes(x = month, y = predicted)) 



grid.arrange(week_plot, month_plot)

```

## Geographical Predictions

We first load the shape files for the community areas and format these in the necessary format to apply a markov random field smooth
```{r}
data_API <- data_API %>% drop_na() %>% filter(!(community_area==0 ))

community_map <- read.socrata("https://data.cityofchicago.org/resource/igwz-8jzy.csv")
community_map <- community_map %>% 
  select(c(the_geom, area = area_numbe)) %>% 
  st_as_sf(wkt = "the_geom") %>%
  mutate(area = as.factor(area)) %>%
  arrange(area)


community_list <- setNames(as.list(community_map$the_geom), nm = community_map$area)
n <- nrow(community_map)
for (i in 1:n){
  i <- as.character(i)
  community_list[[i]] <- unlist(st_coordinates(community_list[[i]]), recursive =TRUE)
}

```

We then obtain the necessary count data, again using the `count_cases()` function:

```{r}
spatial_counts <- df %>% count_cases(location_level = "community_area")  #%>% mutate(community_area = as.factor(community_area))

spatial_model <- gam(count ~ s(month, bs = "cc") + year + s(community_area, bs = "mrf", xt = list(polys = community_list)), data = spatial_counts, family = "poisson")


```

### Incorporating Socio-Economic Indicators
The Chicago Data Portal also contains a dataset with three variables for each community area:

- `percent_households_below_poverty`: Percentage of households living the federal poverty line
- `per_capita_income_`: This is an estimation, calculated by aggregating incomes and dividing by the total population
- `hardship_index`: A score from 1-100 (a higher score indicates a greater level of hardship), incorporating 6 socio-economic indicators.



```{r}
socio_ind <- read.socrata("https://data.cityofchicago.org/resource/i9hv-en6g.csv")
socio_ind <- socio_ind %>% select(-c(community_area_name)) %>% mutate(ca = as.factor(ca))
colnames(socio_ind) = c("ca", "poverty_rate", "income", "hardship_index")
head(socio_ind)
```

We would expect these to be correlated, hence we can do a correlation plot, including the average number of monthly crimes
```{r}
average_crimes <- spatial_counts %>%  
  arrange(community_area) %>%
  group_by(community_area) %>% 
  dplyr::summarise(average = mean(count))

community_info <- left_join(average_crimes, socio_ind, by = c("community_area" = "ca"))


library(corrplot)
plot_data <-  community_info %>% select(-community_area) 
corrplot(cor(plot_data))

```



```{r}
spatial_counts <- spatial_counts %>% left_join(socio_ind, by = c("community_area" = "ca"))

spatial_socio_model <- gam(count ~ s(month, bs = "cc") + year + s(community_area, bs = "mrf", xt = list(polys = community_list)) +hardship_index, data = spatial_counts, family = "poisson")
summary(spatial_socio_model)
```
